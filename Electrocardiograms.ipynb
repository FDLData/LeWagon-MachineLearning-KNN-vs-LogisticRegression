{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Import the [`electrocardiograms.csv`](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_dataset.csv) dataset and display its first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.520599</td>\n",
       "      <td>0.548689</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.664794</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.852060</td>\n",
       "      <td>0.897004</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.970037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.823970</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0.576779</td>\n",
       "      <td>0.597378</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.513109</td>\n",
       "      <td>0.423221</td>\n",
       "      <td>0.277154</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.355805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>0.308929</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>0.291071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283929</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.226786</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.173214</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.167857</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.310714</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.341071</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.358929</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.308929</td>\n",
       "      <td>0.360714</td>\n",
       "      <td>0.455357</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.146429</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.246429</td>\n",
       "      <td>0.301786</td>\n",
       "      <td>0.351786</td>\n",
       "      <td>0.382143</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.398214</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.244780</td>\n",
       "      <td>0.230858</td>\n",
       "      <td>0.216937</td>\n",
       "      <td>0.209977</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.193735</td>\n",
       "      <td>0.187935</td>\n",
       "      <td>0.179814</td>\n",
       "      <td>0.177494</td>\n",
       "      <td>0.160093</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>0.132251</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.107889</td>\n",
       "      <td>0.106729</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>0.096288</td>\n",
       "      <td>0.075406</td>\n",
       "      <td>0.066125</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.112529</td>\n",
       "      <td>0.155452</td>\n",
       "      <td>0.196056</td>\n",
       "      <td>0.220418</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>0.256380</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.259861</td>\n",
       "      <td>0.261021</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.265661</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.277262</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.280742</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.286543</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.298144</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.306264</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.319026</td>\n",
       "      <td>0.328306</td>\n",
       "      <td>0.341067</td>\n",
       "      <td>0.352668</td>\n",
       "      <td>0.37007</td>\n",
       "      <td>0.390951</td>\n",
       "      <td>0.385151</td>\n",
       "      <td>0.387471</td>\n",
       "      <td>0.37587</td>\n",
       "      <td>0.338747</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.402552</td>\n",
       "      <td>0.62181</td>\n",
       "      <td>0.790023</td>\n",
       "      <td>0.75174</td>\n",
       "      <td>0.468677</td>\n",
       "      <td>0.267981</td>\n",
       "      <td>0.349188</td>\n",
       "      <td>0.356148</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.330745</td>\n",
       "      <td>0.343168</td>\n",
       "      <td>0.355590</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.411491</td>\n",
       "      <td>0.405280</td>\n",
       "      <td>0.395963</td>\n",
       "      <td>0.377329</td>\n",
       "      <td>0.377329</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.375776</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.374224</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.408385</td>\n",
       "      <td>0.416149</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.470497</td>\n",
       "      <td>0.451863</td>\n",
       "      <td>0.459627</td>\n",
       "      <td>0.453416</td>\n",
       "      <td>0.427019</td>\n",
       "      <td>0.399068</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.354037</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.388199</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.614907</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.349379</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.301242</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>0.222420</td>\n",
       "      <td>0.259786</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.282918</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.275801</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.334520</td>\n",
       "      <td>0.357651</td>\n",
       "      <td>0.380783</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>0.435943</td>\n",
       "      <td>0.464413</td>\n",
       "      <td>0.476868</td>\n",
       "      <td>0.491103</td>\n",
       "      <td>0.508897</td>\n",
       "      <td>0.501779</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>0.483986</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.457295</td>\n",
       "      <td>0.430605</td>\n",
       "      <td>0.416370</td>\n",
       "      <td>0.407473</td>\n",
       "      <td>0.386121</td>\n",
       "      <td>0.359431</td>\n",
       "      <td>0.350534</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.322064</td>\n",
       "      <td>0.318505</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.316726</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.304270</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.300712</td>\n",
       "      <td>0.309609</td>\n",
       "      <td>0.323843</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.320285</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.274021</td>\n",
       "      <td>0.266904</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.261566</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.272242</td>\n",
       "      <td>0.277580</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>0.850534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976868</td>\n",
       "      <td>0.542705</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>0.185053</td>\n",
       "      <td>0.218861</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>0.204626</td>\n",
       "      <td>0.209964</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>0.197509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0  0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1  1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2  0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3  0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4  0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "\n",
       "        x_8       x_9      x_10      x_11      x_12      x_13      x_14  \\\n",
       "0  0.413858  0.426966  0.485019  0.511236  0.520599  0.548689  0.599251   \n",
       "1  0.346429  0.314286  0.305357  0.308929  0.305357  0.291071  0.285714   \n",
       "2  0.656613  0.421114  0.288863  0.290023  0.269142  0.244780  0.230858   \n",
       "3  0.177019  0.270186  0.313665  0.307453  0.312112  0.312112  0.313665   \n",
       "4  0.108541  0.145907  0.192171  0.222420  0.259786  0.279359  0.282918   \n",
       "\n",
       "       x_15      x_16      x_17      x_18      x_19      x_20      x_21  \\\n",
       "0  0.606742  0.640449  0.664794  0.730337  0.780899  0.852060  0.897004   \n",
       "1  0.283929  0.271429  0.255357  0.264286  0.260714  0.251786  0.241071   \n",
       "2  0.216937  0.209977  0.206497  0.193735  0.187935  0.179814  0.177494   \n",
       "3  0.315217  0.319876  0.316770  0.312112  0.313665  0.319876  0.316770   \n",
       "4  0.279359  0.275801  0.281139  0.288256  0.286477  0.281139  0.279359   \n",
       "\n",
       "       x_22      x_23      x_24      x_25      x_26      x_27      x_28  \\\n",
       "0  0.953184  0.970037  1.000000  0.992509  0.985019  0.943820  0.898876   \n",
       "1  0.226786  0.217857  0.200000  0.173214  0.164286  0.160714  0.155357   \n",
       "2  0.160093  0.142691  0.133411  0.132251  0.121810  0.107889  0.106729   \n",
       "3  0.307453  0.313665  0.315217  0.315217  0.322981  0.330745  0.343168   \n",
       "4  0.290036  0.291815  0.297153  0.313167  0.334520  0.357651  0.380783   \n",
       "\n",
       "       x_29      x_30      x_31      x_32      x_33      x_34      x_35  \\\n",
       "0  0.823970  0.752809  0.711610  0.666667  0.602996  0.576779  0.597378   \n",
       "1  0.141071  0.144643  0.155357  0.167857  0.175000  0.192857  0.223214   \n",
       "2  0.113689  0.096288  0.075406  0.066125  0.048724  0.022042  0.000000   \n",
       "3  0.355590  0.366460  0.380435  0.394410  0.406832  0.406832  0.411491   \n",
       "4  0.405694  0.435943  0.464413  0.476868  0.491103  0.508897  0.501779   \n",
       "\n",
       "       x_36      x_37      x_38      x_39      x_40      x_41      x_42  \\\n",
       "0  0.670412  0.595506  0.513109  0.423221  0.277154  0.119850  0.082397   \n",
       "1  0.251786  0.255357  0.276786  0.310714  0.323214  0.323214  0.326786   \n",
       "2  0.002320  0.024362  0.046404  0.067285  0.112529  0.155452  0.196056   \n",
       "3  0.405280  0.395963  0.377329  0.377329  0.378882  0.369565  0.363354   \n",
       "4  0.496441  0.483986  0.471530  0.457295  0.430605  0.416370  0.407473   \n",
       "\n",
       "       x_43      x_44      x_45      x_46      x_47      x_48      x_49  \\\n",
       "0  0.022472  0.039326  0.054307  0.063670  0.198502  0.303371  0.355805   \n",
       "1  0.342857  0.346429  0.339286  0.342857  0.348214  0.346429  0.335714   \n",
       "2  0.220418  0.241299  0.256380  0.257541  0.252900  0.257541  0.262181   \n",
       "3  0.366460  0.366460  0.361801  0.357143  0.366460  0.369565  0.363354   \n",
       "4  0.386121  0.359431  0.350534  0.354093  0.341637  0.330961  0.327402   \n",
       "\n",
       "       x_50      x_51      x_52      x_53      x_54      x_55      x_56  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.335714  0.339286  0.341071  0.342857  0.357143  0.358929  0.328571   \n",
       "2  0.257541  0.259861  0.261021  0.269142  0.265661  0.263341  0.263341   \n",
       "3  0.361801  0.366460  0.372671  0.371118  0.369565  0.369565  0.378882   \n",
       "4  0.330961  0.327402  0.313167  0.314947  0.322064  0.318505  0.313167   \n",
       "\n",
       "       x_57      x_58      x_59      x_60      x_61      x_62      x_63  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.308929  0.360714  0.455357  0.457143  0.366071  0.205357  0.114286   \n",
       "2  0.271462  0.270302  0.270302  0.273782  0.278422  0.278422  0.271462   \n",
       "3  0.366460  0.357143  0.371118  0.375776  0.372671  0.364907  0.369565   \n",
       "4  0.311388  0.316726  0.311388  0.302491  0.298932  0.307829  0.304270   \n",
       "\n",
       "       x_64      x_65      x_66      x_67      x_68      x_69      x_70  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.048214  0.000000  0.041071  0.101786  0.146429  0.187500  0.246429   \n",
       "2  0.273782  0.278422  0.279582  0.273782  0.277262  0.279582  0.279582   \n",
       "3  0.374224  0.371118  0.372671  0.380435  0.389752  0.394410  0.408385   \n",
       "4  0.295374  0.290036  0.298932  0.291815  0.290036  0.290036  0.295374   \n",
       "\n",
       "       x_71      x_72      x_73      x_74      x_75      x_76      x_77  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.301786  0.351786  0.382143  0.387500  0.398214  0.407143  0.407143   \n",
       "2  0.278422  0.278422  0.285383  0.283063  0.280742  0.283063  0.287703   \n",
       "3  0.416149  0.439441  0.456522  0.470497  0.451863  0.459627  0.453416   \n",
       "4  0.288256  0.290036  0.288256  0.288256  0.288256  0.286477  0.291815   \n",
       "\n",
       "       x_78      x_79      x_80      x_81      x_82      x_83      x_84  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.410714  0.421429  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.286543  0.283063  0.287703  0.291183  0.293503  0.290023  0.291183   \n",
       "3  0.427019  0.399068  0.394410  0.369565  0.354037  0.363354  0.364907   \n",
       "4  0.297153  0.302491  0.300712  0.309609  0.323843  0.330961  0.327402   \n",
       "\n",
       "       x_85      x_86      x_87      x_88      x_89      x_90      x_91  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.296984  0.294664  0.290023  0.290023  0.295824  0.291183  0.293503   \n",
       "3  0.366460  0.364907  0.388199  0.535714  0.734472  0.911491  1.000000   \n",
       "4  0.320285  0.314947  0.295374  0.281139  0.274021  0.266904  0.263345   \n",
       "\n",
       "       x_92      x_93      x_94      x_95      x_96      x_97      x_98  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.293503  0.300464  0.301624  0.296984  0.294664  0.300464  0.294664   \n",
       "3  0.919255  0.614907  0.406832  0.372671  0.349379  0.315217  0.304348   \n",
       "4  0.261566  0.263345  0.272242  0.277580  0.295374  0.354093  0.471530   \n",
       "\n",
       "       x_99     x_100     x_101     x_102     x_103     x_104     x_105  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.293503  0.299304  0.303944  0.300464  0.294664  0.299304  0.307425   \n",
       "3  0.313665  0.312112  0.304348  0.298137  0.301242  0.307453  0.298137   \n",
       "4  0.658363  0.850534  1.000000  0.976868  0.542705  0.193950  0.185053   \n",
       "\n",
       "      x_106     x_107     x_108     x_109     x_110     x_111     x_112  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.301624  0.300464  0.293503  0.303944  0.303944  0.298144  0.296984   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.218861  0.224199  0.201068  0.204626  0.209964  0.201068  0.197509   \n",
       "\n",
       "      x_113     x_114     x_115     x_116     x_117     x_118     x_119  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.303944  0.306264  0.300464  0.301624  0.309745  0.312065  0.307425   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_120     x_121     x_122     x_123     x_124     x_125     x_126  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.302784  0.310905  0.308585  0.299304  0.301624  0.307425  0.310905   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_127     x_128     x_129     x_130     x_131     x_132     x_133  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.305104  0.308585  0.313225  0.310905  0.309745  0.309745  0.317865   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_134     x_135     x_136     x_137     x_138     x_139     x_140  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.315545  0.310905  0.312065  0.317865  0.319026  0.328306  0.341067   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_141    x_142     x_143     x_144     x_145    x_146     x_147  \\\n",
       "0  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "2  0.352668  0.37007  0.390951  0.385151  0.387471  0.37587  0.338747   \n",
       "3  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "      x_148     x_149     x_150     x_151     x_152     x_153     x_154  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.312065  0.308585  0.312065  0.307425  0.301624  0.308585  0.307425   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_155     x_156     x_157     x_158    x_159     x_160    x_161  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "2  0.300464  0.283063  0.301624  0.402552  0.62181  0.790023  0.75174   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "\n",
       "      x_162     x_163     x_164     x_165     x_166     x_167     x_168  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.468677  0.267981  0.349188  0.356148  0.313225  0.295824  0.305104   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_169     x_170     x_171     x_172     x_173     x_174     x_175  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.301624  0.302784  0.294664  0.295824  0.300464  0.296984  0.293503   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_176     x_177     x_178     x_179     x_180     x_181  x_182  x_183  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "2  0.290023  0.296984  0.300464  0.294664  0.295824  0.301624    0.0    0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "\n",
       "   x_184  x_185  x_186  x_187  target  \n",
       "0    0.0    0.0    0.0    0.0       1  \n",
       "1    0.0    0.0    0.0    0.0       1  \n",
       "2    0.0    0.0    0.0    0.0       1  \n",
       "3    0.0    0.0    0.0    0.0       1  \n",
       "4    0.0    0.0    0.0    0.0       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_dataset.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’“ Each observation of the dataset is a sequence of measured heartbeats, taken from a patient's electrocardiogram (ECG).\n",
    "\n",
    "ðŸŽ¯ The target is binary and defines whether the heartbeat shows:\n",
    "* a risk of cardiovascular disease ðŸ”´ (1)\n",
    "* or not ðŸŸ¢ (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question** â“\n",
    "\n",
    "Plot an observation of each target class to get a visual idea of what the numbers represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(data['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Questions** â“\n",
    "\n",
    "* How many observations of at-risk heartbeats are there? Save your answer as `at_risk_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_risk_count = len(data[data['target'] == 1])\n",
    "at_risk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many observations of healthy heartbeats are there? Save your answer as `healthy_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_count = len(data[data['target'] == 0])\n",
    "healthy_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘©ðŸ»â€ðŸ« In certain cases, the class balance is representative of the true class distribution. This is the case here: the vast majority of people actually have healthy hearts. In such case, we preserve the class distribution to train the model based on reality, and adapt our modeling approach accordingly.\n",
    "\n",
    "[Centers for Disease Control and Prevention - Heart Disease Facts](https://www.cdc.gov/heartdisease/facts.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/florencetersier/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/florencetersier/code/FDLData/data-electrocardiograms/tests\n",
      "plugins: anyio-3.6.1, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_class_balance.py::TestClass_balance::test_at_risk_count \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "test_class_balance.py::TestClass_balance::test_healthy_count \u001b[32mPASSED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/class_balance.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed class_balance step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('class_balance',\n",
    "                         healthy = healthy_count,\n",
    "                         at_risk = at_risk_count)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¯ Your task is to **flag heartbeats that are at risk of cardiovascular diseases.**\n",
    "\n",
    "ðŸ‘‡ Let's start by investigating the performance of a `LogisticRegression` on that task. Use a ***cross-validation to evaluate the model*** on the following metrics:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.151037</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.938922</td>\n",
       "      <td>0.296552</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.418491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.456254</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.938922</td>\n",
       "      <td>0.355172</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.462921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.136300</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.939944</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.471910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.814169</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.938410</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.440835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.589204</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.939688</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.429952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_recall  test_precision   test_f1\n",
       "0  1.151037    0.004327       0.938922     0.296552        0.710744  0.418491\n",
       "1  1.456254    0.006650       0.938922     0.355172        0.664516  0.462921\n",
       "2  1.136300    0.003790       0.939944     0.362069        0.677419  0.471910\n",
       "3  1.814169    0.009280       0.938410     0.328720        0.669014  0.440835\n",
       "4  1.589204    0.003582       0.939688     0.307958        0.712000  0.429952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=5, scoring=['accuracy',\n",
    "                                     'recall', \n",
    "                                     'precision',\n",
    "                                     'f1'])\n",
    "\n",
    "cv_results_score = pd.DataFrame(cv_results)\n",
    "cv_results_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Ratio of correct predictions)** â“ \n",
    "\n",
    "What is the ratio of correct predictions for this model ? Save your answer under variable name `correct_pred_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391771019677997"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred_ratio = cv_results_score['test_accuracy'].mean()\n",
    "correct_pred_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Ability to flag at-risk patients)** â“ \n",
    "\n",
    "What percentage of at-risk heartbeats is the model able to flag? Save your answer under variable name `flag_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3300942608280635"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_ratio = cv_results_score['test_recall'].mean()\n",
    "flag_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Ability to flag correctly)** â“ \n",
    "\n",
    "When the model signals an at-risk heartbeat, how often is it correct? Save your answer under variable name `correct_detection_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6867386740061804"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_detection_ratio = cv_results_score['test_precision'].mean()\n",
    "correct_detection_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Detecting as many at-risk patients as possible without too many false alarms)** â“ \n",
    "\n",
    "What is the model's ability to flag as many at-risk heartbeats as possible while limiting false alarms?  Save your answer under variable name `aggregated_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44482198050033483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_metric = cv_results_score['test_f1'].mean()\n",
    "aggregated_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/florencetersier/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/florencetersier/code/FDLData/data-electrocardiograms/tests\n",
      "plugins: anyio-3.6.1, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_accuracy \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_f1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_recall \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/logistic_regression_evaluation.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed logistic_regression_evaluation step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('logistic_regression_evaluation',\n",
    "                         accuracy = correct_pred_ratio,\n",
    "                         recall = flag_ratio,\n",
    "                         precision = correct_detection_ratio,\n",
    "                         f1 = aggregated_metric)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–¶ï¸ Run the following cell before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should have noticed that the model was able to predict correctly in 94 cases out of 100. \n",
      "However, it was able to capture only 33.0 % of the at-risk patients\n",
      "Why ? Let's print a confusion matrix!\n"
     ]
    }
   ],
   "source": [
    "print(f\"You should have noticed that the model was able to predict correctly in {int(round(correct_pred_ratio,2)*100)} cases out of 100. \")\n",
    "\n",
    "print(f\"However, it was able to capture only {round(flag_ratio,2)*100} % of the at-risk patients\")\n",
    "\n",
    "print(\"Why ? Let's print a confusion matrix!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Using `plot_confusion_matrix` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html)),  visualize the predictions breakdown of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Hints</summary>\n",
    "\n",
    "    \n",
    "1. [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)    \n",
    "2. ['ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)\n",
    "    \n",
    "- Don't forget to to go back to the **Holdout method** to [`train-test-split`]((https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) your dataset and look at the confusion matrix on the test set.  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5346</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     0    1\n",
       "actual              \n",
       "0          5346   85\n",
       "1           307  132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame({\"actual\": y_test,\n",
    "                           \"predicted\": preds})\n",
    "\n",
    "confusion_matrix = pd.crosstab(index= results_df['actual'],\n",
    "                               columns = results_df['predicted'])\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ The confusion matrix should show that the model is influenced by the class imbalance: it predicts the heartbeats to be healthy most of the time. Due to this behaviour, the model is often correct and has a **high accuracy**. However, this also causes it to miss out on many at-risk heartbeats: it has **bad recall**...\n",
    "\n",
    "ðŸ‘‰ This model is therefore poor at the task of **flagging at-risk observations**.\n",
    "\n",
    "â—ï¸ Don't be fooled by the accuracy and look at the metric that corresponds to your task! â—ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Classification Model Selection)** â“ \n",
    "\n",
    "Would a default KNN classifier perform better at the task of flagging at-risk observations?\n",
    "\n",
    "Save the you answer under `best_model` as \"KNN\" or \"LogisticRegression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861998466649629"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=5)\n",
    "\n",
    "knn_score = cv_results['test_score'].mean()\n",
    "knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"KNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1683333d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "k_score = []\n",
    "\n",
    "for k in range(2,26,1):\n",
    "    X = data.drop('target', axis=1)\n",
    "    y = data['target']\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    cv_results = cross_validate(model, X, y, cv=5)\n",
    "    k_score.append(cv_results['test_score'].mean())\n",
    "\n",
    "plt.plot(k_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ª For this ECG dataset, the KNN Classifier should have a much higher recall than the LogisticRegression and therefore is better suited for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/florencetersier/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/florencetersier/code/FDLData/data-electrocardiograms/tests\n",
      "plugins: anyio-3.6.1, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_best_model.py::TestBest_model::test_best_model \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/best_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed best_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('best_model',\n",
    "                         model = best_model)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the KNN model thanks to its higherbest recall, let's have a look at the other classification performance metrics>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Classification Report)** â“\n",
    "\n",
    "Print out a [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) of the KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> ðŸ’¡ <i>Hint</i>  </summary>\n",
    "    \n",
    "* You will need to pass the predictions of the model to a `classification_report`.\n",
    "    \n",
    "* SkLearn's [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) might help ðŸ˜‰\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18117\n",
      "           1       0.97      0.84      0.90      1448\n",
      "\n",
      "    accuracy                           0.99     19565\n",
      "   macro avg       0.98      0.92      0.95     19565\n",
      "weighted avg       0.99      0.99      0.99     19565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X,y)\n",
    "\n",
    "y_true = y\n",
    "y_pred = cross_val_predict(model, X,y)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Reading the report)** â“\n",
    "\n",
    "\n",
    "Among the heartbeats predicted at-risk, what is the ratio of correct predictions ? \n",
    "\n",
    "In mathematical terms, can you read the ratio $ \\frac{TP}{TP + FP} $ in the report? What is the name of this classification metrics ? \n",
    "\n",
    "Save your answer as a float under `correct_at_risk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Precision\n",
    "correct_at_risk_predictions = 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/florencetersier/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/florencetersier/code/FDLData/data-electrocardiograms/tests\n",
      "plugins: anyio-3.6.1, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_precision.py::TestPrecision::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m                  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/precision.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed precision step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('precision',\n",
    "                         precision = correct_at_risk_predictions)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Predicting)** â“\n",
    "\n",
    "A patient comes to you for a second opinion because  he was told that based on his heartbeats, this patient may be at-risk.  \n",
    "\n",
    "According to your optimal model, is he at-risk or not?  \n",
    "\n",
    "Save the prediction of your model under variable name `prediction` as \"at risk\" or \"healthy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.192744</td>\n",
       "      <td>0.147392</td>\n",
       "      <td>0.129252</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.00907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.113379</td>\n",
       "      <td>0.160998</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.208617</td>\n",
       "      <td>0.219955</td>\n",
       "      <td>0.240363</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.24263</td>\n",
       "      <td>0.249433</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.256236</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.292517</td>\n",
       "      <td>0.303855</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.319728</td>\n",
       "      <td>0.297052</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.371882</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.29932</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.256236</td>\n",
       "      <td>0.247166</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2  x_3       x_4       x_5       x_6       x_7       x_8  \\\n",
       "0  0.904762  0.993197  1.0  0.956916  0.902494  0.857143  0.802721  0.777778   \n",
       "\n",
       "        x_9      x_10      x_11      x_12      x_13      x_14      x_15  \\\n",
       "0  0.709751  0.557823  0.321995  0.192744  0.147392  0.129252  0.099773   \n",
       "\n",
       "       x_16      x_17      x_18      x_19      x_20      x_21      x_22  \\\n",
       "0  0.092971  0.068027  0.068027  0.061224  0.040816  0.034014  0.027211   \n",
       "\n",
       "       x_23     x_24  x_25      x_26  x_27      x_28      x_29      x_30  \\\n",
       "0  0.013605  0.00907   0.0  0.006803   0.0  0.011338  0.015873  0.031746   \n",
       "\n",
       "       x_31      x_32      x_33      x_34      x_35      x_36      x_37  \\\n",
       "0  0.054422  0.092971  0.113379  0.160998  0.185941  0.208617  0.219955   \n",
       "\n",
       "       x_38      x_39      x_40      x_41      x_42      x_43      x_44  \\\n",
       "0  0.240363  0.231293  0.226757  0.231293  0.238095  0.235828  0.235828   \n",
       "\n",
       "      x_45      x_46      x_47      x_48      x_49      x_50      x_51  \\\n",
       "0  0.24263  0.249433  0.253968  0.258503  0.258503  0.256236  0.253968   \n",
       "\n",
       "       x_52      x_53      x_54      x_55      x_56      x_57      x_58  \\\n",
       "0  0.265306  0.263039  0.272109  0.265306  0.260771  0.263039  0.267574   \n",
       "\n",
       "       x_59      x_60      x_61      x_62      x_63      x_64      x_65  \\\n",
       "0  0.267574  0.274376  0.258503  0.265306  0.263039  0.267574  0.272109   \n",
       "\n",
       "       x_66      x_67      x_68      x_69      x_70      x_71      x_72  \\\n",
       "0  0.263039  0.260771  0.274376  0.269841  0.274376  0.276644  0.269841   \n",
       "\n",
       "       x_73      x_74      x_75      x_76      x_77      x_78      x_79  \\\n",
       "0  0.267574  0.274376  0.292517  0.303855  0.321995  0.337868  0.337868   \n",
       "\n",
       "       x_80      x_81      x_82      x_83      x_84      x_85      x_86  \\\n",
       "0  0.340136  0.319728  0.297052  0.285714  0.269841  0.269841  0.274376   \n",
       "\n",
       "       x_87      x_88      x_89      x_90      x_91      x_92      x_93  \\\n",
       "0  0.269841  0.274376  0.267574  0.260771  0.371882  0.639456  0.959184   \n",
       "\n",
       "       x_94      x_95     x_96      x_97      x_98      x_99     x_100  \\\n",
       "0  0.807256  0.444444  0.29932  0.272109  0.278912  0.253968  0.258503   \n",
       "\n",
       "      x_101     x_102     x_103     x_104     x_105     x_106  x_107  x_108  \\\n",
       "0  0.251701  0.256236  0.247166  0.265306  0.265306  0.267574    0.0    0.0   \n",
       "\n",
       "   x_109  x_110  x_111  x_112  x_113  x_114  x_115  x_116  x_117  x_118  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_119  x_120  x_121  x_122  x_123  x_124  x_125  x_126  x_127  x_128  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_129  x_130  x_131  x_132  x_133  x_134  x_135  x_136  x_137  x_138  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_139  x_140  x_141  x_142  x_143  x_144  x_145  x_146  x_147  x_148  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_149  x_150  x_151  x_152  x_153  x_154  x_155  x_156  x_157  x_158  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_159  x_160  x_161  x_162  x_163  x_164  x_165  x_166  x_167  x_168  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_169  x_170  x_171  x_172  x_173  x_174  x_175  x_176  x_177  x_178  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_179  x_180  x_181  x_182  x_183  x_184  x_185  x_186  x_187  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_patient = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_new_patient.csv')\n",
    "new_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X,y)\n",
    "\n",
    "model.predict(new_patient)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = \"at risk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/florencetersier/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/florencetersier/code/FDLData/data-electrocardiograms/tests\n",
      "plugins: anyio-3.6.1, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_prediction.py::TestPrediction::test_prediction_at_risk \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('prediction',\n",
    "                         prediction = prediction)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ Congratulations!\n",
    "\n",
    "ðŸ’¾ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "ðŸš€ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2352172e6ea988fd88dfcc10b834c5bcaa2937548cc931608b5edc504ebc2cb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
